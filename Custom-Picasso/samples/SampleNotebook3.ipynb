{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Notebook 3 for Picasso\n",
    "This notebook shows how to perform HDBSCAN clustering with picasso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the localizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11975 locs.\n"
     ]
    }
   ],
   "source": [
    "from picasso import io\n",
    "path = 'testdata_locs.hdf5'\n",
    "locs, info = io.load_locs(path)\n",
    "\n",
    "print('Loaded {} locs.'.format(len(locs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDBSCAN wrapper for locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import HDBSCAN as _HDBSCAN\n",
    "import numpy as _np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from picasso import lib as _lib\n",
    "\n",
    "# Clustering with HDBSCAN\n",
    "\n",
    "def hdbscan(locs, min_samples, min_cluster_size):\n",
    "    print(\"Identifying clusters...\")\n",
    "    if hasattr(locs, \"z\"):\n",
    "        print(\"z-coordinates detected\")\n",
    "        pixelsize = int(input(\"Enter the pixelsize in nm/px:\"))\n",
    "        locs = locs[\n",
    "            _np.isfinite(locs.x) & _np.isfinite(locs.y) & _np.isfinite(locs.z)\n",
    "        ]\n",
    "        X = _np.vstack((locs.x, locs.y, locs.z / pixelsize)).T\n",
    "        db = _HDBSCAN(\n",
    "            min_samples=min_samples, min_cluster_size=min_cluster_size\n",
    "        ).fit(X)\n",
    "        group = _np.int32(db.labels_)  # int32 for Origin compatiblity\n",
    "        locs = _lib.append_to_rec(locs, group, \"group\")\n",
    "        locs = locs[locs.group != -1]\n",
    "        print(\"Generating cluster information...\")\n",
    "        groups = _np.unique(locs.group)\n",
    "        n_groups = len(groups)\n",
    "        mean_frame = _np.zeros(n_groups)\n",
    "        std_frame = _np.zeros(n_groups)\n",
    "        com_x = _np.zeros(n_groups)\n",
    "        com_y = _np.zeros(n_groups)\n",
    "        com_z = _np.zeros(n_groups)\n",
    "        std_x = _np.zeros(n_groups)\n",
    "        std_y = _np.zeros(n_groups)\n",
    "        std_z = _np.zeros(n_groups)\n",
    "        convex_hull = _np.zeros(n_groups)\n",
    "        volume = _np.zeros(n_groups)\n",
    "        n = _np.zeros(n_groups, dtype=_np.int32)\n",
    "        for i, group in enumerate(groups):\n",
    "            group_locs = locs[locs.group == i]\n",
    "            mean_frame[i] = _np.mean(group_locs.frame)\n",
    "            com_x[i] = _np.mean(group_locs.x)\n",
    "            com_y[i] = _np.mean(group_locs.y)\n",
    "            com_z[i] = _np.mean(group_locs.z)\n",
    "            std_frame[i] = _np.std(group_locs.frame)\n",
    "            std_x[i] = _np.std(group_locs.x)\n",
    "            std_y[i] = _np.std(group_locs.y)\n",
    "            std_z[i] = _np.std(group_locs.z)\n",
    "            n[i] = len(group_locs)\n",
    "            X_group = _np.stack(\n",
    "                [group_locs.x, group_locs.y, group_locs.z / pixelsize], axis=0\n",
    "            ).T\n",
    "            volume[i] = (\n",
    "                _np.power(\n",
    "                    (std_x[i] + std_y[i] + (std_z[i] / pixelsize)) / 3 * 2, 3\n",
    "                )\n",
    "                * _np.pi\n",
    "                * 4\n",
    "                / 3\n",
    "            )\n",
    "            try:\n",
    "                hull = ConvexHull(X_group)\n",
    "                convex_hull[i] = hull.volume\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                convex_hull[i] = 0\n",
    "        clusters = _np.rec.array(\n",
    "            (\n",
    "                groups,\n",
    "                convex_hull,\n",
    "                volume,\n",
    "                mean_frame,\n",
    "                com_x,\n",
    "                com_y,\n",
    "                com_z,\n",
    "                std_frame,\n",
    "                std_x,\n",
    "                std_y,\n",
    "                std_z,\n",
    "                n,\n",
    "            ),\n",
    "            dtype=[\n",
    "                (\"groups\", groups.dtype),\n",
    "                (\"convex_hull\", \"f4\"),\n",
    "                (\"volume\", \"f4\"),\n",
    "                (\"mean_frame\", \"f4\"),\n",
    "                (\"com_x\", \"f4\"),\n",
    "                (\"com_y\", \"f4\"),\n",
    "                (\"com_z\", \"f4\"),\n",
    "                (\"std_frame\", \"f4\"),\n",
    "                (\"std_x\", \"f4\"),\n",
    "                (\"std_y\", \"f4\"),\n",
    "                (\"std_z\", \"f4\"),\n",
    "                (\"n\", \"i4\"),\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        locs = locs[_np.isfinite(locs.x) & _np.isfinite(locs.y)]\n",
    "        X = _np.vstack((locs.x, locs.y)).T\n",
    "        db = _HDBSCAN(\n",
    "            min_samples=min_samples, min_cluster_size=min_cluster_size\n",
    "        ).fit(X)\n",
    "        group = _np.int32(db.labels_)  # int32 for Origin compatiblity\n",
    "        locs = _lib.append_to_rec(locs, group, \"group\")\n",
    "        locs = locs[locs.group != -1]\n",
    "        print(\"Generating cluster information...\")\n",
    "        groups = _np.unique(locs.group)\n",
    "        n_groups = len(groups)\n",
    "        mean_frame = _np.zeros(n_groups)\n",
    "        std_frame = _np.zeros(n_groups)\n",
    "        com_x = _np.zeros(n_groups)\n",
    "        com_y = _np.zeros(n_groups)\n",
    "        std_x = _np.zeros(n_groups)\n",
    "        std_y = _np.zeros(n_groups)\n",
    "        convex_hull = _np.zeros(n_groups)\n",
    "        area = _np.zeros(n_groups)\n",
    "        n = _np.zeros(n_groups, dtype=_np.int32)\n",
    "        for i, group in enumerate(groups):\n",
    "            group_locs = locs[locs.group == i]\n",
    "            mean_frame[i] = _np.mean(group_locs.frame)\n",
    "            com_x[i] = _np.mean(group_locs.x)\n",
    "            com_y[i] = _np.mean(group_locs.y)\n",
    "            std_frame[i] = _np.std(group_locs.frame)\n",
    "            std_x[i] = _np.std(group_locs.x)\n",
    "            std_y[i] = _np.std(group_locs.y)\n",
    "            n[i] = len(group_locs)\n",
    "            X_group = _np.stack([group_locs.x, group_locs.y], axis=0).T\n",
    "            area[i] = _np.power((std_x[i] + std_y[i]), 2) * _np.pi\n",
    "            try:\n",
    "                hull = ConvexHull(X_group)\n",
    "                convex_hull[i] = hull.volume\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                convex_hull[i] = 0\n",
    "        clusters = _np.rec.array(\n",
    "            (\n",
    "                groups,\n",
    "                convex_hull,\n",
    "                area,\n",
    "                mean_frame,\n",
    "                com_x,\n",
    "                com_y,\n",
    "                std_frame,\n",
    "                std_x,\n",
    "                std_y,\n",
    "                n,\n",
    "            ),\n",
    "            dtype=[\n",
    "                (\"groups\", groups.dtype),\n",
    "                (\"convex_hull\", \"f4\"),\n",
    "                (\"area\", \"f4\"),\n",
    "                (\"mean_frame\", \"f4\"),\n",
    "                (\"com_x\", \"f4\"),\n",
    "                (\"com_y\", \"f4\"),\n",
    "                (\"std_frame\", \"f4\"),\n",
    "                (\"std_x\", \"f4\"),\n",
    "                (\"std_y\", \"f4\"),\n",
    "                (\"n\", \"i4\"),\n",
    "            ],\n",
    "        )\n",
    "    return clusters, locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying clusters...\n",
      "Generating cluster information...\n"
     ]
    }
   ],
   "source": [
    "min_samples = 10\n",
    "min_cluster_size = 10\n",
    "clusters, locs = hdbscan(locs, min_samples, min_cluster_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from picasso import io\n",
    "import os\n",
    "from h5py import File\n",
    "\n",
    "base, ext = os.path.splitext(path)\n",
    "dbscan_info = {\n",
    "    \"Generated by\": \"Picasso HDBSCAN\",\n",
    "    \"Min samples\": min_samples,\n",
    "    \"Min cluster size\": min_cluster_size,\n",
    "}\n",
    "info.append(dbscan_info)\n",
    "io.save_locs(base + \"_dbscan.hdf5\", locs, info)\n",
    "with File(base + \"_dbclusters.hdf5\", \"w\") as clusters_file:\n",
    "    clusters_file.create_dataset(\"clusters\", data=clusters)\n",
    "print('Complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:picasso]",
   "language": "python",
   "name": "conda-env-picasso-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
